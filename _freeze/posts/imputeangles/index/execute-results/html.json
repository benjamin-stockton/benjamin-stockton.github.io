{
  "hash": "566cd7f6e24e75877d28e3952070448a",
  "result": {
    "markdown": "---\ntitle: \"How to Use imputeangles\"\nauthor: \"Ben Stockton\"\neditor: visual\nbibliography: references.bib\ndraft: true\n---\n\n\nIn this post, I will provide a brief introduction to using multiple imputation (MI) and then share an example analysis of pitch movement using my `imputeangles` package.\n\nMost statistical analysis methods are designed with complete data in mind, however real-world data is often incomplete with observations missing due to nonresponse, censoring, or measurement issues. The incomplete data cannot be directly analyzed with the complete data statistical methods. While there are methods designed to model the incomplete data with a modified method, the convenience and widely available of implementations it would be highly beneficial to complete the incomplete data. This could be accomplished by removing incomplete cases and performing complete case analysis (CCA), but this could throw out lots of useful data [@schafer2002].\n\n## Multiple Imputation\n\nImputation is the process of replacing the missing values with values deterministically calculated by the observed data or with values drawn from a probability distribution shaped by the observed data. Two common, but not theoretically valid way to do this are mean imputation (replace with the sample mean or regression predicted values) [@schafer1999multiple] or last observation carried forward (LOCF) for time series or longitudinal data [@moritz2022]. These methods are performed a single time to create a singly imputed (SI) data set. Alternatively, we could with random draws from the observed data or from a predictive distribution based on the observed data. These imputations are worse in terms of providing accurate predictions for the missing value, however they do reflect the uncertainty of the missing value. So repeatedly imputing the missing values to create multiple imputed data sets can propagate the uncertainty to the analysis.\n\nThis process is called by Multiple Imputation (MI) and was initially developed by Donald Rubin in the 1970s and 1980s for nonresponse in surveys [@rubin1978, @rubin1987], and then extended to more analysis contexts since the 1990s [@li2006analysis, @harel2003strategies]. The foundation of MI is a three stage process.\n\n1.  Impute - Fill in the missing values with random samples from a predictive distribution (posterior predictive draws theoretically preferred) to create $M$ completed data sets.\n\n2.  Analyze - Analyze each of the $M$ data sets with a complete data method to estimate a quantity of interest $Q$ using estimate $\\hat{Q}_m$ and its squared standard error $U_m = SE(\\hat{Q})^2$.\n\n3.  Combine - Use Rubin's Rules to combine the estimates and variances to perform inference on the quantity of interest $Q$.\n\n\n    ```{=tex}\n    \\begin{align*} \\label{eq-rubins-rules}\n        \\bar{Q} &= \\frac{1}{M} \\sum_{m=1}^M \\hat{Q}_m \\\\\n        \\bar{U} &= \\frac{1}{M} \\sum_{m=1}^M U_m \\\\\n        B &= \\frac{1}{M-1} \\sum_{m=1}^M (\\hat{Q}_m - \\bar{Q})^2 \\\\\n        T &= \\bar{U} + (1 + \\frac{1}{M}) B\n    \\end{align*}\n    ```\n\n\nUnder a set of assumptions[^1], the inferences produced by MI will be unbiased, more efficient than CCA, and confidence valid. These combination rules have been developed for sample means, sample mean differences, regression coefficients, correlation coefficients, and more [@buuren2018 Sec. 5.2].\n\n[^1]: Without making modifications to the core MI procedure, we have to assume normality for $\\hat{Q}$, ignorability (missing at random and independent priors for the missingness mechanism and data model), and that all assumptions for the imputation procedure are satisfied.\n\n## Pitch Movement\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mice)\nlibrary(Amelia)\nlibrary(ggplot2)\nlibrary(ggthemes)\nlibrary(dplyr)\nlibrary(broom.mixed)\nlibrary(imputeangles)\ntheme_set(theme_bw())\n\n# pitches <- readr::read_csv()\n```\n:::\n\n\nNow we'll take a look at an example of how to perform MI in practice in comparison to CCA. We have a data set of $N =$ caught pitches (swing and called strikes, balls, or hit by pitches) pitches from the 2023 MLB season with measurements for the pitch outcome, pitch velocity and spin direction and rate at release, release point, horizontal and vertical break, location at the plate, as well as the identity of the batter, pitcher, and ballpark. We will model the pitch outcome based on the other measurements while using random effects for the batter, pitcher, and ballpark. In this analysis our quantity of interest is the effect of spin rate $\\beta_{SpinRate}$ on the pitch outcome given the pitch was not fouled off or put in play which will be estimated using a mixed effects logistic regression model.\n\nMultiple imputation will be performed using the chained equations or fully conditional specification with the `mice` R package [@buuren2010mice] with estimates pooled by the `broom.mixed` R package. The inline data will be imputed by `method = \"norm\"` which uses linear regression. The angular data, spin rate, will be imputed by `method = \"bpnreg` which uses Bayesian projected normal regression [@cremers2021] from my `imputeangles` package.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}