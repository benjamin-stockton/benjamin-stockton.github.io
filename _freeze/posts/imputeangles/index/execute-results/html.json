{
  "hash": "52fd59a446425618e618ad342ba5d59e",
  "result": {
    "markdown": "---\ntitle: \"How to Use imputeangles\"\nauthor: \"Ben Stockton\"\neditor: visual\nbibliography: references.bib\ndraft: true\ncache: true\n---\n\n\nIn this post, I will provide a brief introduction to using multiple imputation (MI) and then share an example analysis of pitch movement using my `imputeangles` package.\n\nMost statistical analysis methods are designed with complete data in mind, however real-world data is often incomplete with observations missing due to nonresponse, censoring, or measurement issues. The incomplete data cannot be directly analyzed with the complete data statistical methods. While there are methods designed to model the incomplete data with a modified method, the convenience and widely available of implementations it would be highly beneficial to complete the incomplete data. This could be accomplished by removing incomplete cases and performing complete case analysis (CCA), but this could throw out lots of useful data [@schafer2002].\n\n## Multiple Imputation\n\nImputation is the process of replacing the missing values with values deterministically calculated by the observed data or with values drawn from a probability distribution shaped by the observed data. Two common, but not theoretically valid way to do this are mean imputation (replace with the sample mean or regression predicted values) [@schafer1999multiple] or last observation carried forward (LOCF) for time series or longitudinal data [@moritz2022]. These methods are performed a single time to create a singly imputed (SI) data set. Alternatively, we could with random draws from the observed data or from a predictive distribution based on the observed data. These imputations are worse in terms of providing accurate predictions for the missing value, however they do reflect the uncertainty of the missing value. So repeatedly imputing the missing values to create multiple imputed data sets can propagate the uncertainty to the analysis.\n\nThis process is called by Multiple Imputation (MI) and was initially developed by Donald Rubin in the 1970s and 1980s for nonresponse in surveys [@rubin1978, @rubin1987], and then extended to more analysis contexts since the 1990s [@li2006analysis, @harel2003strategies]. The foundation of MI is a three stage process.\n\n1.  Impute - Fill in the missing values with random samples from a predictive distribution (posterior predictive draws theoretically preferred) to create $M$ completed data sets.\n\n2.  Analyze - Analyze each of the $M$ data sets with a complete data method to estimate a quantity of interest $Q$ using estimate $\\hat{Q}_m$ and its squared standard error $U_m = SE(\\hat{Q})^2$.\n\n3.  Combine - Use Rubin's Rules to combine the estimates and variances to perform inference on the quantity of interest $Q$.\n\n\n    ```{=tex}\n    \\begin{align*} \\label{eq-rubins-rules}\n        \\bar{Q} &= \\frac{1}{M} \\sum_{m=1}^M \\hat{Q}_m \\\\\n        \\bar{U} &= \\frac{1}{M} \\sum_{m=1}^M U_m \\\\\n        B &= \\frac{1}{M-1} \\sum_{m=1}^M (\\hat{Q}_m - \\bar{Q})^2 \\\\\n        T &= \\bar{U} + (1 + \\frac{1}{M}) B\n    \\end{align*}\n    ```\n\n\nUnder a set of assumptions[^1], the inferences produced by MI will be unbiased, more efficient than CCA, and confidence valid. These combination rules have been developed for sample means, sample mean differences, regression coefficients, correlation coefficients, and more [@buuren2018 Sec. 5.2].\n\n[^1]: Without making modifications to the core MI procedure, we have to assume normality for $\\hat{Q}$, ignorability (missing at random and independent priors for the missingness mechanism and data model), and that all assumptions for the imputation procedure are satisfied.\n\n## Pitch Movement\n\n\n::: {.cell hash='index_cache/html/load-pitch-data-no-run_426973969b9d1d903ebd8b0c9ee54eee'}\n\n```{.r .cell-code}\nlibrary(mice)\nlibrary(Amelia)\nlibrary(ggplot2)\nlibrary(ggthemes)\nlibrary(dplyr)\nlibrary(broom.mixed)\nlibrary(imputeangles)\ntheme_set(theme_bw())\n\nperalta_id <- baseballr::playerid_lookup(last_name = \"Peralta\",\n                                         first_name = \"Freddy\") |> \n  dplyr::pull(mlbam_id)\nburnes_id <- baseballr::playerid_lookup(last_name = \"Burnes\", \n                                        first_name = \"Corbin\") |> \n  dplyr::pull(mlbam_id)\nmiley_id <- baseballr::playerid_lookup(last_name = \"Miley\", \n                                       first_name = \"Wade\") |> \n  dplyr::pull(mlbam_id)\nrea_id <- baseballr::playerid_lookup(last_name = \"Rea\", \n                                     first_name = \"Colin\") |> \n  dplyr::pull(mlbam_id)\nteheran_id <- 527054\nhouser_id <- baseballr::playerid_lookup(last_name = \"Houser\", \n                                        first_name = \"Adrian\") |> \n  dplyr::pull(mlbam_id)\nwoodruff_id <- baseballr::playerid_lookup(last_name = \"Woodruff\", \n                                          first_name = \"Brandon\") |> \n  dplyr::pull(mlbam_id)\n\nids_list <- list(peralta_id, burnes_id, rea_id, houser_id, \n                 miley_id, teheran_id, woodruff_id)\n\n# pitches <- readr::read_csv()\npitches <- lapply(ids_list, function(id) {\n    baseballr::statcast_search(start_date = \"2023-03-01\",\n                               end_dat = \"2023-10-31\",\n                               player_type = \"pitcher\", playerid = id)\n    }) |>\n    bind_rows() |>\n    select(\n        game_date, pitcher, batter, game_type, home_team, away_team, \n       pitch_type, type, release_speed, release_spin_rate, release_extension,\n       spin_axis, release_pos_x, release_pos_z, plate_x, plate_z,\n       player_name, events, description, launch_angle, launch_speed\n    ) |>\n    filter(\n        game_type == \"R\", \n        type != \"X\"\n    ) |>\n    select(-game_type)\n\nreadr::write_csv(pitches, \"data/brewers_sp_2023_pitches.csv\")\n```\n:::\n\n::: {.cell hash='index_cache/html/load-pitch-data_6e0c33b51d62fbda1d86b81c3be11be4'}\n\n:::\n\n::: {.cell hash='index_cache/html/fig-miss-map_70cdbbd8318ef3665629ca71ed776c97'}\n\n```{.r .cell-code}\npitches |>\n    select(\n        pitch_type, release_speed, release_spin_rate, spin_axis,\n        release_extension, plate_x, plate_z  \n    ) |>\n    VIM::matrixplot()\n```\n\n::: {.cell-output-display}\n![Missinginess matrix plot where red indicates missingness in that observation.](index_files/figure-html/fig-miss-map-1.png){#fig-miss-map width=672}\n:::\n:::\n\n\nNow we'll take a look at an example of how to perform MI in practice in comparison to CCA. We have a data set of $N =$ 10544 caught pitches (swing and called strikes, balls, or hit by pitches) pitches from the 2023 MLB season with measurements for the pitch outcome, pitch velocity and spin direction and rate at release, release point, horizontal and vertical break, location at the plate, as well as the identity of the batter, pitcher, and ballpark. We will model the pitch outcome based on the other measurements while using random effects for the batter, pitcher, and ballpark. In this analysis our quantity of interest is the effect of spin rate $\\beta_{SpinRate}$ on the pitch outcome given the pitch was not fouled off or put in play which will be estimated using a mixed effects logistic regression model.\n\n\n::: {.cell hash='index_cache/html/pitches-thrown-norun_6f72abb74a9142b014a5d2676006a60e'}\n\n```{.r .cell-code}\npitches |>\n    group_by(player_name) |>\n    summarize(n_pitches = n(),\n              n_fastball = sum(pitch_type %in% c(\"FC\", \"FF\", \"FS\", \"SI\")),\n              n_offspeed = sum(pitch_type %in% c(\"CH\", \"CU\", \"SL\", \"ST\")),\n              n_missing = sum(is.na(pitch_type))) \n```\n:::\n\n::: {#tbl-pitches-thrown .cell tbl-cap='Number of pitches thrown by each starting pitcher.' hash='index_cache/html/tbl-pitches-thrown_79d066bdc195e13cb5ce3280c2058e19'}\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> player_name </th>\n   <th style=\"text-align:right;\"> n_pitches </th>\n   <th style=\"text-align:right;\"> n_fastball </th>\n   <th style=\"text-align:right;\"> n_offspeed </th>\n   <th style=\"text-align:right;\"> n_missing </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Burnes, Corbin </td>\n   <td style=\"text-align:right;\"> 2569 </td>\n   <td style=\"text-align:right;\"> 1583 </td>\n   <td style=\"text-align:right;\"> 986 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Houser, Adrian </td>\n   <td style=\"text-align:right;\"> 1506 </td>\n   <td style=\"text-align:right;\"> 1005 </td>\n   <td style=\"text-align:right;\"> 427 </td>\n   <td style=\"text-align:right;\"> 74 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Miley, Wade </td>\n   <td style=\"text-align:right;\"> 1506 </td>\n   <td style=\"text-align:right;\"> 1040 </td>\n   <td style=\"text-align:right;\"> 466 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Peralta, Freddy </td>\n   <td style=\"text-align:right;\"> 2430 </td>\n   <td style=\"text-align:right;\"> 1253 </td>\n   <td style=\"text-align:right;\"> 1177 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Rea, Colin </td>\n   <td style=\"text-align:right;\"> 1651 </td>\n   <td style=\"text-align:right;\"> 1334 </td>\n   <td style=\"text-align:right;\"> 317 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Woodruff, Brandon </td>\n   <td style=\"text-align:right;\"> 882 </td>\n   <td style=\"text-align:right;\"> 554 </td>\n   <td style=\"text-align:right;\"> 328 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nMultiple imputation will be performed using the chained equations or fully conditional specification with the `mice` R package [@buuren2010mice] with estimates pooled by the `broom.mixed` R package [@bolkerBroomMixed2022]. The inline data will be imputed by `method = \"pmm\"` which uses predictive mean matching. The angular data, spin rate, will be imputed by `method = \"pnregid\"` which uses Bayesian projected normal regression with a constrained covariance matrix $\\Sigma$ [@hernandez-stumpfhauser2017] from my `imputeangles` package.\n\nTo impute with the projected normal regression, we have to specify to `mice` which variable is angular and which variables are the $\\cos$ and $\\sin$ of the angular variable. We can do this by doing an empty run of `mice()` by setting the maximum number of cycles to 0. Then we extract the methods vector and predictor matrix to modify and then pass to our actual run of `mice()` with $M = 5$ imputations and $c = 10$ cycles.\n\n\n::: {.cell hash='index_cache/html/set-up-mice_ca2bcfa006de2b6a89b45be092f6fe1b'}\n\n```{.r .cell-code}\npitches[,c(\"release_speed\", \"release_extension\", \"release_spin_rate\")] <- scale(pitches[,c(\"release_speed\", \"release_extension\", \"release_spin_rate\")])\npitches <- pitches |>\n    mutate(\n        rate_cos_spin = release_spin_rate * cos(spin_axis),\n        rate_sin_spin = release_spin_rate * sin(spin_axis)\n    )\n\nimp0 <- mice(pitches, m = 1, maxit = 0, method = \"pmm\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Number of logged events: 6\n```\n:::\n\n```{.r .cell-code}\nmethods <- imp0$method\nmethods[\"spin_axis\"] <- \"bpnreg\"\nmethods[\"cos_spin\"] <- \"~cos(spin_axis)\"\nmethods[\"sin_spin\"] <- \"~sin(spin_axis)\"\nmethods[\"cos_2spin\"] <- \"~cos(2*spin_axis)\"\nmethods[\"sin_2spin\"] <- \"~sin(2*spin_axis)\"\nmethods\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          game_date             pitcher              batter           home_team \n                 \"\"                  \"\"                  \"\"                  \"\" \n          away_team          pitch_type                type       release_speed \n                 \"\"                  \"\"                  \"\"               \"pmm\" \n  release_spin_rate   release_extension           spin_axis       release_pos_x \n              \"pmm\"               \"pmm\"            \"bpnreg\"               \"pmm\" \n      release_pos_z             plate_x             plate_z         player_name \n              \"pmm\"               \"pmm\"               \"pmm\"                  \"\" \n             events         description            cos_spin            sin_spin \n                 \"\"                  \"\"   \"~cos(spin_axis)\"   \"~sin(spin_axis)\" \n          cos_2spin           sin_2spin       rate_cos_spin       rate_sin_spin \n\"~cos(2*spin_axis)\" \"~sin(2*spin_axis)\"               \"pmm\"               \"pmm\" \n```\n:::\n\n```{.r .cell-code}\npred_mat <- imp0$predictorMatrix\npred_mat[,c(\"game_date\", \"pitcher\", \"batter\", \"home_team\", \"away_team\", \"type\",\n            \"events\", \"player_name\", \"description\", \"spin_axis\")] <- 0\npred_mat[\"spin_axis\", c(\"cos_spin\", \"sin_spin\", \"cos_2spin\", \"sin_2spin\")] <- 0\npred_mat[c(\"cos_spin\", \"sin_spin\", \"cos_2spin\", \"sin_2spin\"), ] <- 0\npred_mat[c(\"cos_spin\", \"sin_spin\", \"cos_2spin\", \"sin_2spin\"), \"spin_axis\"] <- 1\n\npred_mat[c(\"spin_axis\", \"cos_spin\", \"sin_spin\"), c(\"spin_axis\", \"cos_spin\", \"sin_spin\", \"release_speed\", \"release_extension\")]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          spin_axis cos_spin sin_spin release_speed release_extension\nspin_axis         0        0        0             1                 1\ncos_spin          1        0        0             0                 0\nsin_spin          1        0        0             0                 0\n```\n:::\n:::\n\n\nAfter setting up the methods vector and predictor matrix, we can run `mice()`.\n\n\n::: {.cell hash='index_cache/html/run-mice-norun_e224cebb058cf84205fa44a43b303879'}\n\n```{.r .cell-code}\nimps <- mice(pitches, m = 5, maxit = 5, method = methods,\n             predictorMatrix = pred_mat, printFlag = FALSE)\n```\n:::\n\n\n\n\nThe logistic regression mixed effects model is then fit to each of the completed data sets. Estimates and their variances are combined with `broom.mixed`.\n\n\n::: {.cell hash='index_cache/html/fit-glmm-imps-norun_1b9299f856f738d33df1f32a0cc5af9d'}\n\n```{.r .cell-code}\nfit <- with(imps, lme4::glmer(type ~ cos_spin + sin_spin + cos_2spin + sin_2spin \n                              + release_speed + release_extension \n                              + plate_x * plate_z + release_pos_x * release_pos_z\n                              + (1 + pitch_type | player_name),\n                              family = binomial(link = \"logit\")))\n\npooled <- pool(fit)\n\nsummary(pooled)\n```\n:::\n\n\n\n::: {#tbl-glmm-pooled .cell tbl-cap='Pooled summary of the fits for the GLMM.' hash='index_cache/html/tbl-glmm-pooled_e23eaeb087f294af42cef2293433ba05'}\n::: {.cell-output-display}\n|Term                        | $\\hat{\\beta}$| $se(\\hat{\\beta})$| LB 95% CI| UB 95% CI|\n|:---------------------------|-------------:|-----------------:|---------:|---------:|\n|(Intercept)                 |       -1.8988|            1.7676|   -5.3654|    1.5678|\n|cos_spin                    |        0.0643|            0.3563|   -0.6341|    0.7628|\n|sin_spin                    |        0.2623|            1.4698|   -2.6239|    3.1485|\n|cos_2spin                   |       -0.0039|            0.4929|   -0.9718|    0.9640|\n|sin_2spin                   |        0.1724|            0.2551|   -0.3276|    0.6725|\n|release_speed               |       -0.0314|            0.0561|   -0.1414|    0.0786|\n|release_extension           |        0.0012|            0.0341|   -0.0656|    0.0681|\n|rate_cos_spin               |       -0.1007|            0.0840|   -0.2654|    0.0640|\n|rate_sin_spin               |        0.1008|            0.0446|    0.0134|    0.1882|\n|plate_x                     |       -1.1104|            0.0659|   -1.2396|   -0.9811|\n|plate_z                     |        0.4396|            0.0272|    0.3863|    0.4929|\n|release_pos_x               |       -0.6002|            0.4430|   -1.4689|    0.2684|\n|release_pos_z               |        0.1745|            0.2194|   -0.2555|    0.6046|\n|plate_x:plate_z             |        0.5631|            0.0291|    0.5061|    0.6201|\n|release_pos_x:release_pos_z |        0.0806|            0.0717|   -0.0600|    0.2212|\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}